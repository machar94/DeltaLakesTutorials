{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%idle_timeout 2880\n",
    "%glue_version 4.0\n",
    "%region us-east-1\n",
    "%number_of_workers 2\n",
    "%worker_type G.1X\n",
    "%session_id_prefix fantasy-football"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%configure\n",
    "{\n",
    "    'datalake-formats': 'delta'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from awsglue.context import GlueContext\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import col, lit, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# When running locally, if you enounter the following error:\n",
    "# ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=GlueReplApp, master=jes) created by __init__ at /tmp/3143887023558129831:505 \n",
    "# \n",
    "# Comment out the sc = SparkContext().getOrCreate() line and try again.\n",
    "sc = SparkContext().getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME='madhav-delta-lake-project-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_total = glueContext.create_data_frame.from_catalog(\n",
    "    database=\"delta_lake\",\n",
    "    table_name=\"top_performers_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through files in an s3 folder with boto3\n",
    "bucket = s3_resource.Bucket(f'{BUCKET_NAME}')\n",
    "\n",
    "for obj in bucket.objects.filter(Prefix='database/raw/', ):\n",
    "\n",
    "    if not obj.key.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    # Get year from file name\n",
    "    year = int(obj.key.split('/')[2].split('.')[0])\n",
    "\n",
    "    # Read csv file from s3 and convert to DataFrame\n",
    "    df = glueContext.create_data_frame.from_options(\n",
    "        connection_type='s3',\n",
    "        connection_options={'paths': [f's3a://{BUCKET_NAME}/{obj.key}']},\n",
    "        format='csv',\n",
    "        format_options={'withHeader': True},\n",
    "        transformation_ctx='datasource0')\n",
    "    \n",
    "    df = df.withColumn(\"FantasyPoints\", df[\"FantasyPoints\"].cast(\"double\"))\n",
    "    \n",
    "    # Create a window specification to get top 12 players by position\n",
    "    # Note: This will actually return all players that have a top 12 fantasy score\n",
    "    # which means that there may be more than 12 players for a given position\n",
    "    windowSpec = Window.partitionBy('Pos').orderBy(df['FantasyPoints'].desc())\n",
    "    \n",
    "    df_csv = df.filter(col(\"Pos\").isin([\"QB\", \"WR\", \"RB\"])) \\\n",
    "        .select('Pos', 'Player', 'FantasyPoints') \\\n",
    "        .withColumn(\"rank\", rank().over(windowSpec)) \\\n",
    "        .filter(col(\"rank\") <= 12)\n",
    "    \n",
    "    # Clean up additional columns and add year\n",
    "    df_csv = df_csv.withColumnRenamed(\"Pos\", \"Position\") \\\n",
    "        .withColumn(\"Year\", lit(year)) \\\n",
    "        .select(\"Year\", \"Position\", \"Player\", \"FantasyPoints\")\n",
    "\n",
    "    df_total = df_total.union(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Write pyspark dataframe to delta lake\n",
    "df_total.write.format(\"delta\").mode(\"overwrite\").save(f\"s3a://{BUCKET_NAME}/database/top_performers_delta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
